{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7dd068-8230-46aa-8e1b-611d12109a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import augment\n",
    "from utils.augment import *\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from utils.dataloader import mel_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdbf60-4e4a-47a2-a671-654af1137621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mel_dataset('/mnt/disks/sdb/dataset', 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b703533-7908-4753-9aec-60bcf01def2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = MixupBYOLA()\n",
    "crop = RandomResizeCrop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d2bb7-dc7d-41d6-910e-84eeaa1fe376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    x_train_1 = []\n",
    "    x_train_2 = []\n",
    "    \n",
    "    for x, y in batch:\n",
    "        x = (np.array(x)+127)/100\n",
    "        x = np.expand_dims(x, axis=-1)\n",
    "        x = crop(mix(x))        \n",
    "        x_train_1.append(x)\n",
    "        \n",
    "    for x, y in batch:\n",
    "        x = (np.array(x)+127)/100\n",
    "        x = np.expand_dims(x, axis=-1)\n",
    "        x = crop(mix(x))        \n",
    "        x_train_2.append(x)\n",
    "            \n",
    "    y_train = [y for _, y in batch]           \n",
    "    return augment.post_norm(np.stack(x_train_1 + x_train_2, axis=0)), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651f3e2-3f58-486c-9b12-c37f2f60ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(data)\n",
    "train_size = int(dataset_size * 0.8)    \n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset, = random_split(data, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=0, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596aa124-ed73-4e89-82f0-9634ea4fe494",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=['k'])\n",
    "def top_k(loss_list, ts, k):\n",
    "    top_k = jnp.argsort(loss_list, axis=1)[:k]\n",
    "    correct = 0\n",
    "    for i in range(ts.shape[0]):\n",
    "        b = (jnp.where(top_k[i,:] == ts[i], jnp.ones((top_k[i,:].shape)), 0)).sum()\n",
    "        correct += b\n",
    "    correct /= ts.shape[0]\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc09ee44-a00e-44a8-a39b-930fc1122a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simclr(num_epochs, **kwargs):\n",
    "    # Create a trainer module with specified hyperparameters\n",
    "    trainer = AudioEncoderTrainer(exmp=jnp.ones((16,48,1876,1)))\n",
    "    trainer.train_model(train_dataloader, test_dataloader, num_epochs=1)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa287d-45ec-4025-bb42-96158690438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_trainer = train_simclr(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81b18c5-fab2-4352-aa02-771a929ce146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb051330-e6b7-4925-8192-9c124b39ba81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mel_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNumpyDataset\u001b[39;00m(\u001b[43mmel_dataset\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# data.TensorDataset for numpy arrays\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marrays \u001b[38;5;241m=\u001b[39m arrays\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mel_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class NumpyDataset(mel_dataset):\n",
    "    # data.TensorDataset for numpy arrays\n",
    "\n",
    "    def __init__(self, *arrays):\n",
    "        self.arrays = arrays\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.arrays[0].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [arr[idx] for arr in self.arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b715646d-0251-4d4e-b7d5-4113ed1be1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_features(encode_fn, data):\n",
    "    # Encode all images\n",
    "    dataset = DataLoader(data, batch_size=16,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=True,\n",
    "                                  num_workers=0,\n",
    "                                  collate_fn=collate_batch)\n",
    "    \n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataset):\n",
    "        batch_feats = encode_fn(batch_imgs)\n",
    "        feats.append(jax.device_get(batch_feats))\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = np.concatenate(feats, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    # Sort images by labels for easier postprocessing later\n",
    "    idxs = labels.argsort()\n",
    "    labels, feats = labels[idxs], feats[idxs]\n",
    "\n",
    "    return NumpyDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8613a2-6df6-4084-9b62-52f8e6b420f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats_simclr = prepare_data_features(encode_fn, train_dataset)\n",
    "test_feats_simclr = prepare_data_features(encode_fn, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de2c468-f927-4b1f-b704-8af369f097bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simclr_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m simclr_model \u001b[38;5;241m=\u001b[39m \u001b[43msimclr_trainer\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbind({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: simclr_trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m      2\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_stats\u001b[39m\u001b[38;5;124m'\u001b[39m: simclr_trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch_stats},\n\u001b[1;32m      3\u001b[0m                                         mutable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_stats\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simclr_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "simclr_model = simclr_trainer.model.bind({'params': simclr_trainer.state.params,\n",
    "                                          'batch_stats': simclr_trainer.state.batch_stats},\n",
    "                                        mutable=['batch_stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41153741-b0d7-4547-8412-bbc797516e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_fn = jax.jit(lambda img: simclr_model.encode(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81fce0b4-dfb7-426b-9b05-57185587a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(batch_size, train_feats_data, test_feats_data, num_epochs=100, **kwargs):\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_feats_data,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   drop_last=True,\n",
    "                                   generator=torch.Generator().manual_seed(42),\n",
    "                                   collate_fn=numpy_collate)\n",
    "    test_loader = DataLoader(test_feats_data,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  drop_last=False,\n",
    "                                  collate_fn=numpy_collate)\n",
    "\n",
    "    # Create a trainer module with specified hyperparameters\n",
    "    trainer = LGTrainer(exmp=next(iter(train_loader))[0],\n",
    "                        # model_suffix=model_suffix,\n",
    "                        **kwargs)\n",
    "    trainer.train_model(train_loader, test_loader, num_epochs=num_epochs)\n",
    "\n",
    "    # Test best model on train and validation set\n",
    "    train_result = trainer.eval_model(train_loader) \n",
    "    test_result = trainer.eval_model(test_loader)\n",
    "    result = {\"train\": train_result[\"acc\"], \"test\": test_result[\"acc\"]}\n",
    "\n",
    "    return trainer, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "681072c0-597e-4dbf-abfd-4c6e4fcad766",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_feats_simclr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m _, result \u001b[38;5;241m=\u001b[39m train_logreg(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m                          train_feats_data\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_feats_simclr\u001b[49m,\n\u001b[1;32m      5\u001b[0m                          test_feats_data\u001b[38;5;241m=\u001b[39mtest_feats_simclr,\n\u001b[1;32m      6\u001b[0m                          num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m      7\u001b[0m                          lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m      8\u001b[0m                          weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m\n\u001b[1;32m      9\u001b[0m                          )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_feats_simclr' is not defined"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "_, result = train_logreg(batch_size=16,\n",
    "                         train_feats_data=train_feats_simclr,\n",
    "                         test_feats_data=test_feats_simclr,\n",
    "                         num_classes=30,\n",
    "                         lr=1e-3,\n",
    "                         weight_decay=1e-3\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334181a-fdac-41d1-b773-08135b51afc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
